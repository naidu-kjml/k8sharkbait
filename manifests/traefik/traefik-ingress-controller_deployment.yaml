---
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  labels:
    k8s-app: traefik-ingress-lb
  name: traefik
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: traefik-ingress-lb
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        k8s-app: traefik-ingress-lb
        name: traefik-ingress-lb
    spec:
      serviceAccountName: traefik
      hostNetwork: true
      nodeSelector:
        # This is pinned to a specific node in our configuration
        kubernetes.io/hostname: robot-ghost-poop-2.xn--9q8h2cq1m.ws
      volumes:
      - name: traefik-cache
        persistentVolumeClaim: 
          claimName: traefik-claim
      - name: traefik-cfg
        configMap:
          name: traefik-cfg
      containers:
      - args:
        - -d
        - --kubernetes
        - --configFile=/config/traefik.toml
        - --logLevel=INFO
        image: traefik:1.7
        imagePullPolicy: Always
        name: traefik-ingress-lb
        env:
        # Traefik's Let's Encrypt configuration requires an API key for our
        # DNS provider. See the sample toml for additional details
        # kubectl create secret generic -n kube-system linode --from-literal="linode api key"
        # but we are using the http-01 challenge so DNS does not matter
        ports:
        - name: http
          containerPort: 80
          hostPort: 80
        - name: https
          containerPort: 443
          hostPort: 443
        - name: admin
          # This matches the "dashboard" entrypoint in traefik-cfg (traefik-configmap.yaml)
          containerPort: 8081
          hostPort: 8081
        resources:
          limits:
            cpu: 50m
            memory: 30Mi
          requests:
            cpu: 50m
            memory: 20Mi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /etc/traefik
          name: traefik-cache
        - mountPath: /config
          name: traefik-cfg
      dnsPolicy: ClusterFirst
      hostNetwork: true
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 60
status: {}
